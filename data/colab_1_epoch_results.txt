[10103/10103 2:07:54, Epoch 1/1]
Step 	Training Loss
50 	0.382300
100 	0.154300
150 	0.140400
200 	0.138400
250 	0.126000
300 	0.109900
350 	0.137500
400 	0.112600
450 	0.115900
500 	0.146000
550 	0.096900
600 	0.103700
650 	0.144900
700 	0.126100
750 	0.107000
800 	0.115300
850 	0.094400
900 	0.069000
950 	0.118900
1000 	0.112800
1050 	0.109200
1100 	0.110300
1150 	0.098200
1200 	0.145000
1250 	0.060600
1300 	0.116100
1350 	0.103300
1400 	0.120500
1450 	0.118200
1500 	0.078900
1550 	0.139600
1600 	0.078700
1650 	0.079900
1700 	0.100600
1750 	0.090400
1800 	0.077500
1850 	0.068900
1900 	0.099500
1950 	0.087000
2000 	0.083400
2050 	0.092400
2100 	0.121300
2150 	0.077800
2200 	0.080900
2250 	0.078000
2300 	0.122000
2350 	0.081600
2400 	0.096900
2450 	0.085100
2500 	0.080300
2550 	0.085100
2600 	0.072600
2650 	0.091400
2700 	0.108600
2750 	0.121300
2800 	0.121100
2850 	0.130400
2900 	0.089100
2950 	0.075400
3000 	0.122500
3050 	0.071100
3100 	0.092600
3150 	0.079500
3200 	0.107800
3250 	0.101600
3300 	0.050400
3350 	0.075200
3400 	0.076200
3450 	0.086800
3500 	0.088100
3550 	0.080700
3600 	0.079300
3650 	0.106200
3700 	0.085100
3750 	0.061200
3800 	0.077000
3850 	0.086800
3900 	0.089700
3950 	0.081600
4000 	0.102100
4050 	0.118800
4100 	0.095900
4150 	0.073600
4200 	0.099900
4250 	0.042700
4300 	0.132600
4350 	0.108700
4400 	0.075200
4450 	0.081100
4500 	0.120600
4550 	0.064100
4600 	0.076200
4650 	0.108000
4700 	0.059400
4750 	0.077900
4800 	0.075200
4850 	0.094100
4900 	0.054800
4950 	0.065700
5000 	0.070000
5050 	0.123600
5100 	0.110700
5150 	0.056300
5200 	0.075900
5250 	0.118300
5300 	0.077700
5350 	0.076900
5400 	0.074100
5450 	0.100900
5500 	0.061600
5550 	0.088900
5600 	0.092100
5650 	0.067100
5700 	0.074000
5750 	0.089700
5800 	0.083800
5850 	0.095600
5900 	0.093200
5950 	0.111400
6000 	0.098700
6050 	0.070600
6100 	0.055900
6150 	0.074800
6200 	0.092200
6250 	0.055900
6300 	0.065300
6350 	0.040600
6400 	0.061400
6450 	0.080500
6500 	0.076400
6550 	0.065200
6600 	0.070100
6650 	0.070100
6700 	0.071500
6750 	0.073000
6800 	0.076800
6850 	0.065600
6900 	0.098600
6950 	0.071400
7000 	0.052000
7050 	0.077100
7100 	0.065200
7150 	0.043000
7200 	0.105400
7250 	0.086000
7300 	0.060700
7350 	0.067900
7400 	0.072100
7450 	0.076800
7500 	0.104000
7550 	0.075600
7600 	0.062800
7650 	0.072200
7700 	0.071300
7750 	0.076800
7800 	0.070200
7850 	0.043800
7900 	0.082600
7950 	0.059300
8000 	0.066900
8050 	0.065100
8100 	0.086600
8150 	0.068500
8200 	0.075600
8250 	0.055200
8300 	0.096900
8350 	0.063500
8400 	0.054600
8450 	0.067400
8500 	0.071900
8550 	0.075500
8600 	0.077300
8650 	0.078800
8700 	0.071100
8750 	0.083900
8800 	0.068600
8850 	0.088300
8900 	0.080400
8950 	0.068600
9000 	0.066200
9050 	0.061800
9100 	0.061600
9150 	0.067900
9200 	0.089300
9250 	0.073300
9300 	0.078400
9350 	0.083900
9400 	0.060000
9450 	0.067300
9500 	0.056600
9550 	0.061800
9600 	0.078400
9650 	0.046900
9700 	0.039300
9750 	0.062200
9800 	0.074200
9850 	0.081900
9900 	0.057100
9950 	0.058000
10000 	0.068000
10050 	0.055100
10100 	0.079100

TrainOutput(global_step=10103, training_loss=0.08643723120609628, metrics={'train_runtime': 7675.0499, 'train_samples_per_second': 21.06, 'train_steps_per_second': 1.316, 'total_flos': 2.141163291655987e+16, 'train_loss': 0.08643723120609628, 'epoch': 1.0})


[2526/2526 10:04]

{'eval_loss': 0.07124733924865723,
 'eval_accuracy': 0.9792873051224944,
 'eval_f1': 0.9819179502689623,
 'eval_runtime': 604.9994,
 'eval_samples_per_second': 66.793,
 'eval_steps_per_second': 4.175,
 'epoch': 1.0}